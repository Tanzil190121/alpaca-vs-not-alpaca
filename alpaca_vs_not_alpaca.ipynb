{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1uYa83tj_tm1"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('/content/drive/MyDrive/new_folder/archive (13).zip','r') as zipObj:\n",
        "  zipObj.extractall(\"/content/drive/MyDrive/Resume\")"
      ],
      "metadata": {
        "id": "0nifjP8R_xFP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def is_image(filename):\n",
        "    try:\n",
        "        img = Image.open(filename)\n",
        "        img.close()\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if not is_image(file_path) or not file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                print(f\"Deleting {file_path}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_folder = r\"/content/drive/MyDrive/Resume/dataset\"\n",
        "    process_folder(target_folder)\n"
      ],
      "metadata": {
        "id": "-8wXLX9wAhV8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"/content/drive/MyDrive/Resume/dataset/alpaca\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OtnFvH7Bniz",
        "outputId": "2cd19df9-0e9e-4ff3-f215-b300604bdace"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"/content/drive/MyDrive/Resume/dataset/not alpaca\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7HxqsMMBuit",
        "outputId": "04436969-4700-4773-f423-a5ba07808ac5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n"
      ],
      "metadata": {
        "id": "IWHUK1phByLW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Resume/dataset\",\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    image_size=(224,224),\n",
        "    batch_size=32,\n",
        "    seed=1337,\n",
        "    shuffle=True,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "\n",
        "\n",
        ")\n",
        "val_ds=image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Resume/dataset',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    image_size=(224,224),\n",
        "    batch_size=32,\n",
        "    seed=1337,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhfQHS1KB7kR",
        "outputId": "0026aca3-cd1a-4ab3-fe3f-9b7be9e25def"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 327 files belonging to 2 classes.\n",
            "Using 262 files for training.\n",
            "Found 327 files belonging to 2 classes.\n",
            "Using 65 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "PTtvzZu1B-yC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,Conv2D,MaxPooling2D"
      ],
      "metadata": {
        "id": "sHlkOUIwDewq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (224, 224)\n",
        "models=Sequential(\n",
        "    [\n",
        "        Conv2D(32,(3,3),activation='relu',input_shape=(image_size[0],image_size[1],3)),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(64,(3,3),activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(128,(3,3),activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Flatten(),\n",
        "        Dense(128,activation='relu'),\n",
        "        Dense(1,activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "models.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "models.fit(train_ds,validation_data=val_ds,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Teqn78uuDwsb",
        "outputId": "7e29c782-d1c5-41e2-fade-a11c3f86ae59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 30s 3s/step - loss: 123.5498 - accuracy: 0.5000 - val_loss: 1.0694 - val_accuracy: 0.4615\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 24s 2s/step - loss: 0.8078 - accuracy: 0.6374 - val_loss: 0.7061 - val_accuracy: 0.5538\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 22s 2s/step - loss: 0.4054 - accuracy: 0.8473 - val_loss: 1.3588 - val_accuracy: 0.4308\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.3135 - accuracy: 0.8511 - val_loss: 0.8548 - val_accuracy: 0.5231\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 22s 2s/step - loss: 0.1856 - accuracy: 0.9427 - val_loss: 1.2173 - val_accuracy: 0.5385\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.1237 - accuracy: 0.9542 - val_loss: 1.5615 - val_accuracy: 0.6923\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 22s 2s/step - loss: 0.0770 - accuracy: 0.9885 - val_loss: 1.3292 - val_accuracy: 0.5385\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 22s 2s/step - loss: 0.0471 - accuracy: 0.9924 - val_loss: 1.6212 - val_accuracy: 0.5692\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 2.2373 - val_accuracy: 0.5846\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 22s 2s/step - loss: 0.0196 - accuracy: 0.9885 - val_loss: 1.8355 - val_accuracy: 0.5692\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78c5f746d0f0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_fcbWFZELcC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}